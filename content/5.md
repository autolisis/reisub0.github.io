Title: Fractal Learning
Date: 2020-10-07
Category: learning
Tags: learning, systems
Status: draft

![tree]({static}/images/tree.gif)

## Part 1 - Complexity

This world is a very complex, interconnected web of systems. We've tried to make sense of this by creating various (seemingly-unrelated) disciplines. With the huge number of disciplines, I think you'll agree with me when I say that it's impossible for any one person to be an expert in all of these fields.

It's turtles all the way down, however, and even as you go deeper into a field, there's still so much complexity that you would despair at the idea of ever really understanding anything even within the confines of one specific field.

Most fields seem to exhibit a fractal pattern. By this, I mean that the more you try to *zoom in* onto a specific aspect of a system, the more detail is revealed. The same is true whether you're talking about economics or physics or biology. A whole new world of detail is revealed at all the different levels.


Of course, when confronted with complexity, our first instinct is to *reduce* and to treat these in isolation, and we've tried to come to terms with the complexity within fields by creating **specializations**, which are essentially sub-fields. 

This is why a microbiologist seems to speak a completely different language from an ecologist. This might make you wonder whether the two fields are even related; one could argue that they both view the world through a radically different set of lenses.

As human knowledge progresses and we're able to understand systems at different levels, we're continuously spawning newer and newer specializations and hyperspecializations.


> The challenge we all face is how to maintain the benefits of breadth, diverse experience, interdisciplinary thinking, and delayed concentration in a world that increasingly incentivizes, even demands, hyperspecialization
>
> From the book Range - David Epstein

Nowhere is this concept clearer than in computer science where incredibly complex systems have been built to deliver cat videos to your screen. There's nothing special about my choice of computer science here, as I'm sure there are similar levels of complexity lurking beneath the surface of any domain.

You could spend years and years in deep study and you still wouldn't really fully *get* how a computer worked. There would always be gaps in your knowledge. Even behind something as seemingly simple as allowing you to read these words on your screen, there is so much hidden complexity. There are towers and towers of abstractions that enable this to happen:

1. Your CPU (essentially a tiny piece of silicon that can't do much but add two numbers together) executed a few million instructions during the time you were reading this sentence. Welcome to Computer Architecture!
2. These instructions are in most cases not understandable by a human. So we invented a "high-level language" and wrote another software to convert this high level language into the instructions. Welcome to Compilers!
3. There are multiple applications running on this system at the same time, somehow somebody (the Operating System) managed to abstract all this away such that the applications are able to pretend that they're the only application running on the system. Similarly, there are other resources (RAM, files, I/O devices) that all need to be shared between the hundreds of programs running on your system. Welcome to Operating Systems!
4. Your device doesn't exist in isolation. In fact, a lot of its capabilities arise in relation with other devices. Just for the purpose of loading this website and viewing it, it had to send signals out into the ether which somehow (like a labelled envelope) found its way to the right servers and then they responded back with the data you were requesting. Welcome to Networks!

In fact, all of the cases above are huge simplifications. I haven't even begun scratching the surface. If you're curious to learn more, [look at how much detail](https://github.com/alex/what-happens-when) is hidden behind a simple Google search.

A short digression here: there is a famous result in psychology on working memory (also called [Miller's Law](https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two)). It suggests that humans can, on average, hold about 7 objects in their short-term memory at one time. Basically, if you're playing around with concepts in your head and thinking about how things relate with one another, there seems to be a cognitive limit of about 7 items.

Of course that is quite fuzzy and it is of course dangerous to generalize too much from any one result. However, I'd suggest that we can take away this lesson from Miller's Law: humans can't hold too many things in their head at the same time. Software systems are very, very complex beasts and it's beyond the scope of any person to hold in their head all the minute details of how something is working. 

So how do you even begin to understand and make sense of things which seems to have so many interconnected pieces?

This is where *Abstraction* comes in. This is one of the fundamental building blocks of Computer Science, Engineering, and Problem Solving in general. Abstraction is when you squint your eyes and treat something as a *black box*. You are temporarily choosing to not care about what's happening inside the black box because other details are more important. 

For an example of abstraction think about *interfaces* to objects you commonly use. A car for example hides a lot of complicated circuitry and machinery, but at the end of the day, all you need to care about is the steering wheel and a couple of pedals. That's the abstract view of a car. I don't care how that car turns these inputs into the multiple complicated outputs of fuel intake, torque etc. I completely ignore that because it's not important to me. I just want to get from point A to point B and I just need to know how to use the interface of the car to achieve the goal.

A well-designed interface (this is true of software interfaces too!) would allow you to focus on fewer aspects of the car and expend lesser *cognitive effort* when driving the car; I'm talking about manual vs automatic vs self-driving cars. 

Sure, that's all well and good, but this article is about *Dealing with Complexity*, not about *Pretending it doesn't exist*. After all, someone does ultimately have to design and work with the underlying complexity ([Tesler's Law](https://en.wikipedia.org/wiki/Law_of_conservation_of_complexity)). You'd be a terrible automobile engineer if you were only able to see a car as its interface!

## Part 2 - Fractal Learning

I first came across this concept in the excellent [IntermezzOS Book](https://intermezzos.github.io/book/second-edition/fractal-learning.html).

> It's impossible to learn everything at once. If you keep digging, you'll find more questions, and digging into those questions leads to more questions... at some point, you have to say "okay, I know enough about this for now, it's time to move on."It's impossible to learn everything at once. If you keep digging, you'll find more questions, and digging into those questions leads to more questions... at some point, you have to say "okay, I know enough about this for now, it's time to move on."



